{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.分析get请求数据以及post请求数据\n",
    "get得到的json数据可以通过base64解码出两张图片:图片背景图以及插图。\n",
    "\n",
    "id信息会在post中\"yzm\"字段用到\n",
    "\n",
    "程序一为还原图片，程序二为叠放图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "import requests\n",
    "url = \"http://202.117.17.144:8080/gen\"\n",
    "r = requests.get(url)\n",
    "print(r.text)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import joblib\n",
    "\"\"\" \n",
    "\n",
    "\"\"\"\n",
    "# url = \"http://202.117.17.144:8080/gen\"\n",
    "# r = requests.get(url)\n",
    "# response_json = r.json()\n",
    "with open(\"request/get.json\") as f:\n",
    "    response_json = json.load(f)\n",
    "start_idx = len(\"data:image/jpeg;base64,\")\n",
    "backgroundImage = response_json[\"captcha\"][\"backgroundImage\"][start_idx:]\n",
    "bgImg = base64.b64decode(backgroundImage)\n",
    "str = time.asctime()\n",
    "with open(\"bgImg.png\",'wb') as f:\n",
    "    f.write(bgImg)\n",
    "start_idx = len(\"data:image/png;base64,\")\n",
    "sliderImage = response_json[\"captcha\"][\"sliderImage\"][start_idx:]\n",
    "sldImg = base64.b64decode(sliderImage)\n",
    "with open(\"resource/sliderImg.png\",'wb') as f:\n",
    "    f.write(sldImg)\n",
    "\n",
    "# joblib.dump(r, 'x.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# 加载图像\n",
    "_img1 = cv2.imread('./img/sliderImg.png')\n",
    "img2 = cv2.imread('./img/bgImg.png')\n",
    "img1 = _img1[0:img2.shape[0],:]\n",
    "pad_w = img2.shape[1] - img1.shape[1] # 计算需要填充的像素数目（图像的宽这一维度上）\n",
    "img1_new = cv2.copyMakeBorder(img1,0,0,0,pad_w,cv2.BORDER_CONSTANT,None,(0,0,0))\n",
    "res = cv2.add(img1_new,img2)\n",
    "\n",
    "cv2.imwrite(\"./img/concat_img.png\",res)\n",
    "# cv2.imshow('imshow',res)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来研究post.json中的内容：startSlidingTime、endSlidingTime、tracklist\n",
    "\n",
    "以下代码可根据post中发送的参数还原出track的动画效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "with open(\"request/post.json\") as f:\n",
    "    track = json.load(f)\n",
    "\n",
    "_start_slide_time = track[\"startSlidingTime\"]\n",
    "_end_slide_time = track[\"endSlidingTime\"]\n",
    "start_slide_time = datetime.datetime.strptime(_start_slide_time, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "end_slide_time = datetime.datetime.strptime(_end_slide_time, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "t = end_slide_time -start_slide_time \n",
    "microseconds = int(t.seconds*1000 + t.microseconds//1000 + 1) \n",
    "fig = plt.figure()\n",
    "plt.xlim(0,200)\n",
    "plt.ylim(-100,100)\n",
    "\n",
    "\n",
    "ims = []\n",
    "tracklist = track[\"trackList\"]\n",
    "i = 0\n",
    "xlist = []\n",
    "ylist = []\n",
    "im = []\n",
    "data_time = int(tracklist[i][\"t\"])\n",
    "    \n",
    "for gif_time in range(0,microseconds,20):\n",
    "    if data_time < gif_time:\n",
    "        x,y = tracklist[i][\"x\"],tracklist[i][\"y\"]\n",
    "        xlist.append(x)\n",
    "        ylist.append(y)\n",
    "        im = plt.plot(xlist,ylist,color=\"black\")\n",
    "        while data_time <= gif_time and i < len(tracklist):\n",
    "            i += 1\n",
    "            data_time = int(tracklist[i][\"t\"])\n",
    "    ims.append(im)\n",
    "# plt.show()\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=20, repeat_delay=1000)\n",
    "ani.save(\"resource/test.gif\", writer='pillow')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x y已经研究清楚了，t的变化是怎样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "with open(\"request/post.json\") as f:\n",
    "    track = json.load(f)\n",
    "t= [item[\"t\"] for item in track[\"trackList\"]] \n",
    "plt.plot(t,color=\"black\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以用 t = k*n 近似这种规律"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "according preliminary exercise, we can draw below conclusions.\n",
    "-  track 中的原点是手指最早触碰屏幕的点 (0，0)\n",
    "-  总时间是 startSlidingTime - endSlidingTime, tracklist 第三个参数是毫秒\n",
    "-  tracklist中type第一个为down，中间为move，最后一个为up\n",
    "-  分析部分已完成，接下来需要cv对缺口的位置识别，识别精度要高\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def identify_gap(bg,tp,out=\"identify.png\"):\n",
    "    '''\n",
    "    bg: 背景图片\n",
    "    tp: 缺口图片\n",
    "    out:输出图片\n",
    "    '''\n",
    "    # 读取背景图片和缺口图片\n",
    "    bg_img = cv2.imread(bg)\n",
    "    tp_img = cv2.imread(tp)\n",
    "    \n",
    "    # 识别图片边缘\n",
    "    bg_edge = cv2.Canny(bg_img, 100, 200)\n",
    "    tp_edge = cv2.Canny(tp_img, 100, 200)\n",
    "    \n",
    "    # 转换图片格式\n",
    "    bg_pic = cv2.cvtColor(bg_edge, cv2.COLOR_GRAY2RGB)\n",
    "    tp_pic = cv2.cvtColor(tp_edge, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # 缺口匹配\n",
    "    res = cv2.matchTemplate(bg_pic, tp_pic, cv2.TM_CCOEFF_NORMED)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res) # 寻找最优匹配\n",
    "    \n",
    "    # 绘制方框\n",
    "    th, tw = tp_pic.shape[:2] \n",
    "    tl = max_loc # 左上角点的坐标\n",
    "    br = (tl[0]+tw,tl[1]+th) # 右下角点的坐标\n",
    "    cv2.rectangle(bg_img, tl, br, (0, 0, 255), 2) # 绘制矩形\n",
    "    cv2.imwrite(out, bg_img) # 保存在本地\n",
    "    \n",
    "    # 返回缺口的X坐标\n",
    "    return tl[0]+tw//2\n",
    "print(identify_gap('resource/bgImg.png','resource/sliderImg.png'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "几个重要参数\n",
    "- bgimg (590,360)\n",
    "- sliderImg (110,360)\n",
    "- 缺口 (374,275)\n",
    "\n",
    "因此该问题已经十分明了。\n",
    "\n",
    "发送参数\"bgImageWidth\":260,\"bgImageHeight\":0,\"sliderImageWidth\":0,\"sliderImageHeight\":159\n",
    "\n",
    "(260,159)为屏幕显示时图片大小，与(590,360)等比\n",
    "\n",
    "理想移动距离：374-110/2 = 319 按照590:260的比例缩放，即得到实际移动距离140\n",
    "在实际操作中，tracklist中\"x\":139，与理论计算一致"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把以上分析整合为API, [slider_yzm.py](./slider_yzm.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yzm.slider_yzm import build_post,identify_gap\n",
    "import json,base64,time,requests\n",
    "r= json.load(open(\"request/get.json\"))\n",
    "response_json  = r\n",
    "start_idx = len(\"data:image/jpeg;base64,\")\n",
    "backgroundImage = response_json[\"captcha\"][\"backgroundImage\"][start_idx:]\n",
    "bgImg = base64.b64decode(backgroundImage)\n",
    "str = time.asctime()\n",
    "with open(\"yzm/img/bgImg.png\",'wb') as f:\n",
    "    f.write(bgImg)\n",
    "start_idx = len(\"data:image/png;base64,\")\n",
    "sliderImage = response_json[\"captcha\"][\"sliderImage\"][start_idx:]\n",
    "sldImg = base64.b64decode(sliderImage)\n",
    "with open(\"yzm/img/sliderImg.png\",'wb') as f:\n",
    "    f.write(sldImg)\n",
    "id = r[\"id\"]\n",
    "bg_shape = [r[\"captcha\"][\"backgroundImageWidth\"] , r[\"captcha\"][\"backgroundImageHeight\"]]\n",
    "slider_shape = [r[\"captcha\"][\"sliderImageWidth\"] , r[\"captcha\"][\"sliderImageHeight\"]]\n",
    "if bg_shape[1] != slider_shape[1]:\n",
    "    slider_shape[1] = bg_shape[1]\n",
    "show_shape = (260,159)\n",
    "k = show_shape[1]/bg_shape[1]\n",
    "# show_shape = bg_shape\n",
    "# k = 1\n",
    "yzm = build_post(show_shape,(round(slider_shape[0]*k),show_shape[1]),k)\n",
    "rp = requests.post(\"http://202.117.17.144:8071/check\",params={'id':id},json=yzm)\n",
    "round(identify_gap('yzm/img/bgImg.png','yzm/img/sliderImg.png') * k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "527f40983acd289a64dfb000e9a2a081519c1abb4eb1b4d7c5ea437a635c1f45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
